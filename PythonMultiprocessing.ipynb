{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Multiprocessing Python Scripts in ArcGIS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "“My script takes too long!!” Do you find yourself making this complaint too often? Well, maybe your script would benefit from multiprocessing! If you’re not sure, this session will dive into what multiprocessing is, the different scenarios where multiprocessing workflows can help speed up processing, and how to practically utilize multiprocessing in ArcGIS. You will learn how to move from, “This is so slow…” to “WOW! That was fast!”.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor\n",
    "\n",
    "<img style=\"float: left; padding: 20px\" alt=\"Image of James Whitacre\" src=\"https://rv0vwg.bn.files.1drv.com/y4mfNzvcpey1Ot55Y1_EO5JCcCTfpRevZkYmvSFvwX0BlusUTJnhAlim7k27-oQdTd6vpRmJoGx1rHy_hDu9m92AVE3VTsjZ4-8Po-zyabpqW7-N9VSInWc2CB1vjHrQCrrg_c9d4YOS9Y06veh6ke84R0QlQWX2zWMal1gaAiq7CFwfumMy8bRmR7SsSn-1msUbasPapjnKEzcRQj-UMPZtw?width=300&height=300&cropmode=none\" width=\"300\" height=\"300\" />\n",
    "\n",
    "### James Whitacre\n",
    "\n",
    "**GIS Research Scientist, Carnegie Museum of Natural History, Powdermill Nature Reserve**\n",
    "\n",
    "whitacrej@canregiemnh.org\n",
    "\n",
    "James Whitacre is the GIS Research Scientist for the Carnegie Museum of Natural History where he manages the GIS Lab at Powdermill Nature Reserve, the Museum’s environmental research center, and supports museum staff and affiliated researchers with geospatial technologies and needs. This is Whitacre’s second appointment at the Museum as he was formerly the GIS Manager from 2011 to 2014. Before returning to the Museum in 2018, Whitacre was the GIS Specialist for the Main Library at the University of Illinois at Urbana-Champaign where he provided GIS consultations for researchers and scholars and taught GIS workshops to promote the use of GIS in research. Whitacre holds a Bachelor of Arts in Zoology from Ohio Wesleyan University and a Master of Science in Geography, concentrating on GIS and cartography, from Indiana University of Pennsylvania.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Talk Data \n",
    "\n",
    "### From GitHub\n",
    "* Go to repo at **https://github.com/whitacrej/**\n",
    "* Click on the **Code** dropdown\n",
    "* Click **Download Zip**\n",
    "* **Extract** zip file to desktop or well-known folder\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "[**I. Introduction to Multiprocessing**](#I.-Introduction-to-Multiprocessing)\n",
    "* [Notes](#Notes)\n",
    "* [Definitions](#Definitions)\n",
    "* [Why Multiprocessing?](#Why-Multiprocessing?)\n",
    "* `[Workflows](#Workflows)` **NEED TO COMPLETE**\n",
    "\n",
    "\n",
    "[**II. Linear Script**](#II.-Linear-Script)\n",
    "* Brief overview of Pamap Lidar data\n",
    "* Measuring processing time in scripts\n",
    "* `for` loops and function iteration\n",
    "\n",
    "\n",
    "[**III. Convert to Multiprocessing Script**](#III.-Convert-to-Multiprocessing-Script)\n",
    "\n",
    "\n",
    "[**IV. Custom Script Tools and Multiprocessing**](#IV.-Custom-Script-Tools-and-Multiprocessing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction to Multiprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I am not an expert on multiprocessing programming\n",
    "    * I have simply found ways to more easily utilize the `multiprocessing` and `threading` Python modules in ArcGIS Python scripts\n",
    "    * I have built on numerous others who are explroing `multiprocessing` and `threading` (see Resources below)\n",
    "    * I am pretty sure I don't follow the `multiprocessing` and `threading` Python modules' rules fully, but my code works! So, this means we are going to be a bit reblellious today, but I would love to get feedback and corrections!\n",
    "    * Please be fogiving of me!! I used these techniques a few months ago, recognized they are super helpful for the GIS community, tried to present them a few times, but then the pandemic...so, I am a bit rusty now...\n",
    "\n",
    "\n",
    "* Resources\n",
    "    * Blog: https://www.esri.com/arcgis-blog/products/analytics/analytics/multiprocessing-with-arcgis-raster-analysis/\n",
    "    * Parallel Python: Multiprocessing with ArcPy (2017): https://www.youtube.com/watch?v=KAzCG6C8-7g\n",
    "    * Vector and Raster Multiprocessing with ArcPy (2018): https://www.youtube.com/watch?v=cin5BOWlAs8\n",
    "\n",
    "\n",
    "* Python is inherently linear\n",
    "    * This means that processes and functions are ran in sequence\n",
    "    * This is important to keep in mind as the helper modules are needed to accomplish non-linear programing techniques\n",
    "\n",
    "\n",
    "* Python and some some ArcGIS datatypes (namely file geodatabases) are not inherently thread-safe\n",
    "    * What does this mean? Well, that can be a bit complicated...I'll try to explain\n",
    "    * The global interpreter lock (GIL) and memory management...I told you it is complicated!\n",
    "    * Locks on file geodatabases can pose problems...\n",
    "\n",
    "\n",
    "* I am not getting into distributed programming...all these examples utilize a single workstation with mulitple cores (btw, most computers utilize multiple cores these days!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program or Script\n",
    "* Executable file consisting of instructions to perform some task\n",
    "* Stored on the disk of your computer (e.g. a '.py' file)\n",
    "\n",
    "\n",
    "### Process\n",
    "* Program loaded into memory with resources needed to operate\n",
    "* Has its own memory space\n",
    "\n",
    "\n",
    "### Thread\n",
    "* Unit of execution within a process\n",
    "* Processes can have multiple threads running\n",
    "* Each thread uses the process’s memory space and shares it with other threads\n",
    "\n",
    "\n",
    "### CPU - Central Processing Unit\n",
    "* This the central chip and circuitry that process programs, data, and information\n",
    "* Let's check it out: Task Manager > Performance > Change Graph to > Logical Processors\n",
    "\n",
    "\n",
    "### Multithreading?\n",
    "\n",
    "* The ability to use two or more CPUs (processors) simultaneously (or concurrently) to run code\n",
    "* The memory usage is independent and not shared between processes\n",
    "* Generally multiprocessing is a bit more expensive than multithreading, but there are resaon for choosing one over the other (we'll get into that...)\n",
    "\n",
    "\n",
    "### Multiprocessing?\n",
    "\n",
    "* The ability to use a single processor to run code concurrently\n",
    "* The memory usage is dependent and can be shared between processes\n",
    "\n",
    "\n",
    "### So....I've heard of Parallel Processing or Concurency...is that different?\n",
    "* No...but there are some technical differences in the terms with many sources seem to be nucanced and inconsistent with their definitions\n",
    "* Essentially we are talking about the simultaneous execution of programming tasks!\n",
    "* Many tools in ArcGIS already have parallel processing integrated and it may not be good to use `multiprocessing` with (I haven't tried those tools...)\n",
    "\n",
    "\n",
    "\n",
    "See the following websites for more info:\n",
    "* https://en.wikipedia.org/wiki/Multiprocessing\n",
    "* https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/\n",
    "* https://www.geeksforgeeks.org/difference-between-multiprocessing-and-multithreading/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Multiprocessing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The need for speed!\n",
    "* Good for larger datasets and file sizes\n",
    "* Improve performance\n",
    "* Scale workflows\n",
    "* Creates multiple **python.exe** instances\n",
    "\n",
    "\n",
    "\n",
    "### Why not...\n",
    "\n",
    "* Some data structures are not condusive to multiprocessing, so this needs to be assessed when designing your workflow\n",
    "* Need to weigh the processing time savings vs. the time to design and write a parallel workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Multiprocesing Workflows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Workflows...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Linear Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example PAMAP Lidar Data\n",
    "\n",
    "* Available Here: https://www.pasda.psu.edu/uci/DataSummary.aspx?dataset=1244\n",
    "\n",
    "* PAMAP LAS Spec: https://www.pasda.psu.edu/uci/FullMetadataDisplay.aspx?file=pamap_lidar_LAS.xml#Entity_and_Attribute_Information\n",
    "\n",
    "* How can we make the LAS files better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psuedo-code\n",
    "\n",
    "1. List LAS Files\n",
    "2. [Classify Ground Points](https://pro.arcgis.com/en/pro-app/latest/tool-reference/3d-analyst/classify-las-ground.htm)\n",
    "3. [Set LAS Class Codes Using Features](https://pro.arcgis.com/en/pro-app/latest/tool-reference/3d-analyst/set-las-class-codes-using-features.htm)\n",
    "\n",
    "## Check LAS stats\n",
    "LAS File: 30001530PAS.las\n",
    "\n",
    "| Classification | Point Count | %     |\n",
    "|----------------|-------------|-------|\n",
    "| 1 Unassigned | 326,373 | 9.74  |\n",
    "| 2  Ground | 1,537,015   | 45.87 |\n",
    "| 8  Model Key/Reserved | 373,467 | 11.14 |\n",
    "| 9  Water | 427 | 0.01 |\n",
    "| 12  Overlap/Reserved | 1,106,553 | 33.02 |\n",
    "| 15  Transmission Tower | 7,323 | 0.22 |\n",
    "\n",
    "\n",
    "## Open Task Manager > CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import Modules '''\n",
    "import arcpy\n",
    "from datetime import datetime, timedelta\n",
    "from ftplib import FTP\n",
    "import os\n",
    "import shutil\n",
    "import winsound\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup folder and gdb paths\n",
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "default_gdb = aprx.defaultGeodatabase\n",
    "home_folder = aprx.homeFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup LAS workspace\n",
    "raw_folder = os.path.join(home_folder, 'LAS\\Raw')\n",
    "\n",
    "# Download PAMAP LAS files\n",
    "ftp = FTP('ftp.pasda.psu.edu')\n",
    "ftp.login()\n",
    "ftp.cwd('pub/pasda/pamap/pamap_lidar/cycle1/LAS/South/2006/30000000')\n",
    "\n",
    "las_zip_files = ['30001530PAS.zip', '30001540PAS.zip', '30001550PAS.zip',\n",
    "                 '31001530PAS.zip', '31001540PAS.zip', '31001550PAS.zip']\n",
    "zip_files = []\n",
    "for file in las_zip_files:\n",
    "    out_file = os.path.join(raw_folder, file)\n",
    "    ftp.retrbinary(f'RETR {file}', open(out_file, 'wb').write)\n",
    "    zip_files.append(out_file)\n",
    "    print(f'Downloaded {file} to {raw_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zip files\n",
    "for file in zip_files:\n",
    "    with zipfile.ZipFile(file, 'r') as zip_file:\n",
    "        zip_file.extractall(raw_folder)\n",
    "        file_name = os.path.split(file)[1]\n",
    "        print(f'Extracted {file_name} to {raw_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy LAS files to LAS root folder\n",
    "walk = os.walk(raw_folder)\n",
    "input_raw_files = [os.path.join(dirpath, filename) for dirpath, dirnames, filenames in walk\n",
    "                   for filename in filenames if filename.endswith('.las')]\n",
    "\n",
    "for f in input_raw_files:\n",
    "    shutil.copy2(f, os.path.split(raw_folder)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LAS Files\n",
    "las_folder = os.path.join(home_folder, 'LAS')\n",
    "\n",
    "walk = arcpy.da.Walk(las_folder, datatype='LasDataset')\n",
    "\n",
    "input_las_files = [os.path.join(dirpath, filename) for dirpath, dirnames, filenames in walk\n",
    "                   for filename in filenames if dirpath == las_folder]\n",
    "\n",
    "print(input_las_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Ground Points\n",
    "\n",
    "start = datetime.now()\n",
    "max_time = timedelta(seconds=0)\n",
    "\n",
    "for las in input_las_files:\n",
    "    las_start = datetime.now()\n",
    "    \n",
    "    arcpy.ddd.ClassifyLasGround(las, 'STANDARD', 'REUSE_GROUND', '1 Meters', 'COMPUTE_STATS')\n",
    "    \n",
    "    las_end = datetime.now()\n",
    "    las_time = las_end - las_start\n",
    "    max_time = las_time if las_time > max_time else max_time\n",
    "    \n",
    "    print(f'{os.path.split(las)[1]} completed in {las_time}.')\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "total_time = end - start\n",
    "\n",
    "avg_time = total_time / len(input_las_files)\n",
    "\n",
    "\n",
    "print(f'Total Time: {total_time}')\n",
    "print(f'Max Time: {max_time}')\n",
    "print(f'Average Time: {avg_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Roads and Bridges\n",
    "roads = os.path.join(default_gdb, 'Roads')\n",
    "bridges = os.path.join(default_gdb, 'Bridges')\n",
    "\n",
    "start = datetime.now()\n",
    "max_time = timedelta(seconds=0)\n",
    "\n",
    "for las in input_las_files:\n",
    "    las_start = datetime.now()\n",
    "    \n",
    "    arcpy.ddd.SetLasClassCodesUsingFeatures(las,\n",
    "        f\"'{roads}' 0 11 NO_CHANGE NO_CHANGE NO_CHANGE NO_CHANGE;'{bridges}' 0 17 NO_CHANGE NO_CHANGE NO_CHANGE NO_CHANGE\", \n",
    "        'COMPUTE_STATS')\n",
    "    \n",
    "    las_end = datetime.now()\n",
    "    las_time = las_end - las_start\n",
    "    max_time = las_time if las_time > max_time else max_time\n",
    "    \n",
    "    print(f'{os.path.split(las)[1]} completed in {las_time}.')\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "total_time = end - start\n",
    "\n",
    "avg_time = total_time / len(input_las_files)\n",
    "\n",
    "\n",
    "print(f'Total Time: {total_time}')\n",
    "print(f'Max Time: {max_time}')\n",
    "print(f'Average Time: {avg_time}')\n",
    "\n",
    "winsound.PlaySound(r'C:\\Windows\\media\\Ring08.wav', winsound.SND_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset LAS workspace\n",
    "raw_folder = os.path.join(home_folder, 'LAS\\Raw')\n",
    "\n",
    "walk = os.walk(raw_folder)\n",
    "input_raw_files = [os.path.join(dirpath, filename) for dirpath, dirnames, filenames in walk\n",
    "                   for filename in filenames if filename.endswith('.las')]\n",
    "\n",
    "for f in input_raw_files:\n",
    "    shutil.copy2(f, os.path.split(raw_folder)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Convert to Multiprocessing Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a our linear workflow figured out, we can assess whether it can be converted to a multiprocessing script. Recall the types of workflows previously.\n",
    "\n",
    "## Steps for multiprocessing conversion\n",
    "\n",
    "1. Identify the code segments that can be multiprocessed (i.e. the `for` loops!)\n",
    "\n",
    "\n",
    "2. Create a custom importable [module](https://www.w3schools.com/python/python_modules.asp) of helper functions\n",
    "    - Custom module will need to recreate the functions (esp. `arcpy` modules) that you will be using for multiprocessing\n",
    "        - The [ArcGIS Tool Reference](https://pro.arcgis.com/en/pro-app/latest/tool-reference/main/arcgis-pro-tool-reference.htm) is VERY IMPORTANT!!\n",
    "        - Know the tool documentation and especially optional parameter values!!!\n",
    "       \n",
    "    - Why is a custom module needed...\n",
    "        - Well, it has to do with code being [pickleable](https://docs.python.org/3.9/library/pickle.html). What is 'pickleable' you ask...ummm...see the link and let me know if you understand! \n",
    "        - What I also know is that the `multiprocessing` module actualy spins up independent instance of Python and executes the code independently from the other processes and the custom module helps with this. \n",
    "\n",
    "    Resources:\n",
    "    \n",
    "    [Multiprocessing using Script tool in Pro](https://community.esri.com/t5/python-questions/multiprocessing-using-script-tool-in-pro/td-p/415708)\n",
    "    \n",
    "    [Can multiprocessing with arcpy be run in a script tool?](https://gis.stackexchange.com/questions/140533/can-multiprocessing-with-arcpy-be-run-in-a-script-tool)\n",
    "\n",
    "\n",
    "3. `import multiprocessing` and custom module into the script\n",
    "\n",
    "\n",
    "4. **Set Multiprocessing Execution Space** (THIS IS VERY IMPORTANT!!!)\n",
    "\n",
    "\n",
    "5. Rewrite `for` loops to create lists of function arguments\n",
    "\n",
    "\n",
    "6. Use [`Pool().starmap`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.starmap) to call functions in custom module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify the code segments that can be multiprocessed (i.e. the `for` loops!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a custom importable [module](https://www.w3schools.com/python/python_modules.asp) of helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `import multiprocessing` and custom module into the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import Modules '''\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Custom Module into Notebook (this is not needed in a script outside of a Notebook)\n",
    "module_path = os.path.join(home_folder, 'Scripts')\n",
    "sys.path.append(module_path) \n",
    "import lidarlas\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Set Multiprocessing Execution Space** (THIS IS VERY IMPORTANT!!!)\n",
    "\n",
    "See https://docs.python.org/3/library/sys.html#sys.exec_prefix for more information about `sys.executable` and `sys.exec_prefix`\n",
    "\n",
    "See https://docs.python.org/3/library/multiprocessing.html#multiprocessing.set_executable to learn more about  `multiprocessing.set_executable()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check Python Execution Space\n",
    "print(sys.executable)\n",
    "print(sys.exec_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the above output tell us about how Python is run?\n",
    "\n",
    "### What will happen if we don't set the `multiprocessing.set_executable()`?\n",
    "\n",
    "BAAAADDDD STUFF MY FRIENDS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set Multiprocessing Execution Space\n",
    "multiprocessing.set_executable(os.path.join(sys.exec_prefix, 'pythonw.exe'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See https://docs.python.org/2/using/windows.html#executing-scripts to learn more about pythonw.exe vs. python.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CPU Count\n",
    "cpu_ct = cpu_count() if len(input_las_files) > cpu_count() else len(input_las_files)\n",
    "print(f'Total CPU Count: {cpu_count()} | File Count: {len(input_las_files)} | CPUs Used: {cpu_ct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rewrite `for` loops to create lists of function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List LAS Files\n",
    "las_folder = os.path.join(home_folder, 'LAS')\n",
    "\n",
    "walk = arcpy.da.Walk(las_folder, datatype='LasDataset')\n",
    "\n",
    "input_las_files = [os.path.join(dirpath, filename) for dirpath, dirnames, filenames in walk\n",
    "                   for filename in filenames if dirpath == las_folder]\n",
    "\n",
    "print(input_las_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite for loops to create lists of function arguments\n",
    "classify_ground_arg = ['STANDARD', 'REUSE_GROUND', '1 Meters', 'COMPUTE_STATS']\n",
    "classify_ground_args = [[las_file] + classify_ground_arg for las_file in input_las_files]\n",
    "\n",
    "print(classify_ground_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use [`Pool().starmap`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.starmap) to call functions in custom module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "# Use Pool().starmap to call functions in custom module\n",
    "with Pool(processes=cpu_ct) as pool:\n",
    "    results = pool.starmap(lidarlas.ClassifyLasGround, classify_ground_args)\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "total_time = end - start\n",
    "\n",
    "avg_time = total_time / len(input_las_files)\n",
    "\n",
    "\n",
    "print(f'Total Time: {total_time}')\n",
    "print(f'Average Time: {avg_time}')\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite for loops to create lists of function arguments\n",
    "roads = os.path.join(default_gdb, 'Roads')\n",
    "bridges = os.path.join(default_gdb, 'Bridges')\n",
    "\n",
    "# Note the data type is list\n",
    "feature_class_arg = [f\"'{roads}' 0 11 NO_CHANGE NO_CHANGE NO_CHANGE NO_CHANGE;'{bridges}' 0 17 NO_CHANGE NO_CHANGE NO_CHANGE NO_CHANGE\"]\n",
    "\n",
    "classify_features_args = [[las_file] + feature_class_arg + ['2,8'] + ['COMPUTE_STATS'] for las_file in input_las_files]\n",
    "\n",
    "print(classify_features_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Roads and Bridges\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "# Use Pool().starmap to call functions in custom module\n",
    "with Pool(processes=cpu_ct) as pool:\n",
    "    results = pool.starmap(lidarlas.SetLasClassCodesUsingFeaturesFiltered, classify_features_args)\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "total_time = end - start\n",
    "\n",
    "avg_time = total_time / len(input_las_files)\n",
    "\n",
    "\n",
    "print(f'Total Time: {total_time}')\n",
    "print(f'Average Time: {avg_time}')\n",
    "\n",
    "print(results)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Custom Script Tools and Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Congratulations***, you're on your way to using Multiprocessing!!!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
